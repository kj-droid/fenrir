from .base_module import BaseModule
import subprocess
import json
import logging

class ExploitFinder(BaseModule):
    def __init__(self):
        super().__init__()
        self.logger = logging.getLogger(self.name)

    def _run_searchsploit(self, search_term):
        """
        Runs searchsploit for a single search term and returns the results.
        """
        if not search_term or len(search_term) < 3: # Avoid overly broad searches
            return []
            
        command = ["searchsploit", "--json", search_term]
        self.logger.info(f"Running command: {' '.join(command)}")
        try:
            result = subprocess.run(command, capture_output=True, text=True, check=True)
            data = json.loads(result.stdout)
            return data.get("RESULTS_EXPLOIT", [])
        except FileNotFoundError:
            self.logger.error("`searchsploit` command not found. Please ensure 'exploitdb' is installed.")
            return [{"Title": "ERROR: searchsploit command not found.", "Path": ""}]
        except Exception as e:
            self.logger.error(f"Searchsploit query failed for '{search_term}': {e}")
            return []

    def run(self, target, ports=None, previous_results=None):
        """
        Finds exploits by querying searchsploit with an intensive, ordered strategy.
        """
        if not previous_results:
            return "Skipping, no previous results provided."

        all_found_exploits = {}
        search_queue = []
        
        # --- FIX: Correctly parse the nested previous_results dictionary ---

        # 1. Extract CVEs from the vulnerability identifier results
        vulnerabilities = previous_results.get('vulnerability_identifier', {})
        if isinstance(vulnerabilities, dict):
            for service_key, cve_list in vulnerabilities.items():
                if isinstance(cve_list, list):
                    for vuln in cve_list:
                        if isinstance(vuln, dict) and vuln.get('cve_id'):
                            search_queue.append(vuln['cve_id'])

        # 2. Extract service and version details from the port scanner results
        port_scan_results = previous_results.get('port_scanner', {})
        if isinstance(port_scan_results, dict):
            for host, host_data in port_scan_results.items():
                if isinstance(host_data, dict) and 'ports' in host_data:
                    for port_info in host_data['ports']:
                        product = port_info.get('product', '').strip()
                        version = port_info.get('version', '').strip()
                        if product:
                            search_queue.append(f"{product} {version}".strip())
                            search_queue.append(product)
                            search_queue.append(product.split(' ')[0])
        
        # --- End of FIX ---

        # De-duplicate the queue while preserving order
        unique_search_terms = list(dict.fromkeys(search_queue))
        if not unique_search_terms:
            return "No keywords or CVEs available to search for exploits."
            
        # Execute searches and compile results
        for term in unique_search_terms:
            results = self._run_searchsploit(term)
            if results:
                if term not in all_found_exploits:
                    all_found_exploits[term] = []
                all_found_exploits[term].extend(results)

        # De-duplicate exploits across different search terms
        final_results = {}
        seen_edb_ids = set()
        for term, exploits in all_found_exploits.items():
            unique_exploits_for_term = []
            for exploit in exploits:
                edb_id = exploit.get("EDB-ID")
                if edb_id and edb_id not in seen_edb_ids:
                    unique_exploits_for_term.append(exploit)
                    seen_edb_ids.add(edb_id)
            if unique_exploits_for_term:
                final_results[term] = unique_exploits_for_term

        return final_results if final_results else "No public exploits found after intensive search."
